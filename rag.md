how faithful are rag models

retrieval augemented generation은 주로 hallucination을 고치기위해, 새로운 사실, 지식을 제공하기 위해 쓰인다.

의문점:
올바른 retrieved 내용을 제공하는 것이 LLM의 error를 실제로 없애는가?

만약 옳지 않은 내용을 받는다면 이 정보를 무시하는 것이 가능한가?

실험 :
LLM의 지식( train과정을 거친) 와 그와 반대되는 retrieved 내용의 줄다리기 (tug of war)을 분석

https://youtube.com/@johannesjolkkonen?si=GXG9190Ikvo-C91r

![image](https://github.com/jinuk0211/llm_project/assets/150532431/a099e1b3-6966-49c6-9e8b-aa97a5f484e5)
